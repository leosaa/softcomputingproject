{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio_processor.ipynb # import the audio_processor module (Trust that groupmates have implemented the module)\n",
    "import model_trainer.ipynb # import the model_trainer module (Trust that groupmates have implemented the module)\n",
    "import tensorflow as tf # import tensorflow for model training\n",
    "\n",
    "import os\n",
    "\n",
    "RAND_SEED = 42\n",
    "SPLIT_RATIO = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every audio file in the dataset, extract the features and store them in a list\n",
    "def prepare_dataset(dataset_path):\n",
    "    features = []\n",
    "\n",
    "    # Extract features for each audio file in the dataset\n",
    "    for audio_filename in os.listdir(dataset_path):\n",
    "        if(not audio_filename.endswith(\".wav\")): # Skip non-wav files\n",
    "            continue\n",
    "        features.append(audio_processor.extract_features(audio_filename))    \n",
    "\n",
    "    return features\n",
    "\n",
    "def get_labels(label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            labels.append(line.strip())\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our extracted features, build our tensors for training\n",
    "def build_tensors(features, labels):\n",
    "    # Convert the features and labels to TensorFlow tensors\n",
    "    # Assuming each extracted feature is a numpy array or list\n",
    "    features_tensor = tf.convert_to_tensor(features, dtype=tf.float32)  # Convert features to tensor\n",
    "    \n",
    "    # Convert labels to one-hot encoded vectors, assuming labels are integers (e.g., [0, 1, 2,...])\n",
    "    num_classes = len(set(labels))  # Get the number of unique emotion labels\n",
    "    labels_tensor = tf.one_hot(labels, depth=num_classes, dtype=tf.float32)  # One-hot encode labels\n",
    "    \n",
    "    return features_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our dataset, pseudo-randomly shuffle the data & split it into training and testing sets\n",
    "def split_dataset(features, labels, ratio=SPLIT_RATIO, seed=RAND_SEED):\n",
    "    # Where features and labels are TensorFlow tensors\n",
    "    # Split the dataset into training and testing sets\n",
    "\n",
    "    size = tf.shape(features)[0]  # Get the size of the dataset\n",
    "\n",
    "    # Shuffle the dataset by generating a random permutation of indices\n",
    "    indices = tf.range(size)  # Generate a range of indices\n",
    "    shuffled_indices = tf.random.shuffle(indices, seed=seed)  # Shuffle the indices\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    train_size = int(size * ratio)  # Calculate the size of the training set\n",
    "    train_indices = shuffled_indices[:train_size]  # Get the training set indices\n",
    "    test_indices = shuffled_indices[train_size:]  # Get the testing set indices\n",
    "\n",
    "    # Extract the training and testing features and labels\n",
    "    train_features = tf.gather(features, train_indices)  # Extract training features\n",
    "    train_labels = tf.gather(labels, train_indices)  # Extract training labels\n",
    "    test_features = tf.gather(features, test_indices)  # Extract testing features\n",
    "    test_labels = tf.gather(labels, test_indices)  # Extract testing labels\n",
    "\n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the extracted features\n",
    "def train_model(features, labels):\n",
    "    return model_trainer.train_model(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './dataset' # Path to the dataset\n",
    "\n",
    "# Build the dataset\n",
    "features = prepare_dataset(PATH)\n",
    "labels = get_labels('{PATH}/labels.txt') # Assuming labels are stored in a text file\n",
    "\n",
    "# Build the tensors\n",
    "features_tensor, labels_tensor = build_tensors(features, labels)\n",
    "\n",
    "# Split the dataset\n",
    "train_features, train_labels, test_features, test_labels = split_dataset(features_tensor, labels_tensor)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(train_features, train_labels)\n",
    "\n",
    "# Test the model\n",
    "model.test_model(test_features, test_labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
